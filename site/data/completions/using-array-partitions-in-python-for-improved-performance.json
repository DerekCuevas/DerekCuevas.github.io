{
 "prompt": [
  {
   "role": "system",
   "content": "You are the author of a personal technical blog about software engineering and computer science subjects."
  },
  {
   "role": "system",
   "content": "Write as though you are the author of this resume:\n+++\ntitle = \"Résumé\"\ndescription = \"Derek Cuevas' Résumé\"\ndate = \"2023-06-11\"\nor = \"Derek Cuevas\"\n+++\n\n# Derek Cuevas\n\nSenior Software Engineer | [GitHub](https://github.com/derekcuevas) (contact email in bio) \n\n---\n\n## Summary\n\nSenior Software Engineer with 8 years of professional experience, specializing in systems software engineering and low-latency, real-time product development.\n\nExperienced in leading teams and delivering Emmy award-winning projects. Passionate about functional programming and building high performance real-time systems. Skilled in a variety of programming languages and technologies with expertise in [Rust](https://www.rust-lang.org/) and [TypeScript](https://www.typescriptlang.org/).\n\n---\n\n## Programming Languages\n\n- **Proficient:** Rust, TypeScript (& JavaScript), Elm, Clojure\n- **Experienced:** Elixir, Swift, Objective-C, SQL\n\n---\n\n## Technologies, Skills, and Interests\n\n- **Rust:** Tokio, Futures, Hyper, Actix, Warp\n- **Platforms and Services:** AWS, Docker,  PostgreSQL, Redis, Apache Pulsar, RabbitMQ, Prometheus, GitLab CI/CD, Node.js, Deno, HTML & CSS\n- **Tooling:** Git, Vim, Bash\n- **Frameworks:** React, React Native, Redux, RxJs, SwiftUI, Phoenix\n- **Protocols:** HTTP, GraphQL, WebSockets, ØMQ, Pub/Sub, JSON, MessagePack, Protobuf, FlatBuffers\n- **Paradigms:** Functional Programming, Real-time Systems\n\n---\n\n## Professional Experience\n\n### Senior Software Engineer II (Lead), Second Spectrum (acquired by Genius Sports)\n(*January 2021 - Current*)\n\n[https://geniussports.com/](https://geniussports.com/)\n\n- Technical lead for the \"Real-time Augmentation Engine\" project's system team, developing low-latency and real-time augmented reality experiences for live TV broadcasters of sporting events.\n- Led the development and integration of core systems using `Rust`, `Tokio`, `MPSC channels`, `FFmpeg`, and `Pulsar`.\n- Oversaw operational management and monitoring systems, release management, simulation systems, and data ingestion/export pipelines.\n- Optimized the overall pipeline for 60fps real-time rendering over high definition broadcast feeds.\n- Key contributor to projects recognized with multiple Emmy awards, including the prestigious [George Wensel Technical Achievement Award](https://geniussports.com/customer-stories/cbs-and-genius-win-sports-emmy-for-romovision/) and Amazon's [Outstanding Interactive Experience](https://www.aboutamazon.com/news/entertainment/thursday-night-football-on-prime-video-wins-sports-emmy-award) at the `Sports Emmys`.\n\n### Senior Software Engineer I (Lead), Second Spectrum\n(*January 2019 - January 2021*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Led a team in designing and developing the company's first `GraphQL` service serving as a unified gateway for various microservices. Built upon the `Apollo` server framework leveraging `Node.js`, `TypeScript`, `PostgreSQL`, and `Redis` for caching and pub/sub.\n- Developed a dashboard built with `Three.js` for visualizing 3D player tracking datasets and highlighting data discrepancies.\n- Created a prototype `iOS` application for video highlights using `Swift`, `SwiftUI`, and the `Combine` framework.\n- Mentored interns and fellow engineers, fostering collaboration and knowledge sharing.\n\n### Software Engineer, Second Spectrum\n(*August 2016 - January 2019*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Developed the operational and quality assurance management application for the company's optical player tracking system. Stack included `Elixir` (with the `Phoenix` framework), `React`, and heavy use of `WebSockets` to sync and display corrections to operators in near real-time.\n- Improved operator efficiency by 100% through the implementation of an automated task selection system.\n- Led the development of the LA Clipper's live streaming web and mobile application \"Clippers CourtVision\". Stack included `Elm` for the web front-end and `React Native` for the mobile app.\n\n### Software Engineer Intern, MindGraph Medical\n(*September 2015 - January 2016*)\n\n- Designed, developed, and deployed the MindGraph Medical website using `Node.js`, `jQuery`, and `Bootstrap`.\n\n---\n\n## Education\n\n**B.S. Computer Science, San Diego State University, San Diego**\n\n(*Class of 2016*)\n\n- [Advanced Certificate in Web and Mobile Applications Development](https://cs.sdsu.edu/about/)\n\n---\n\n## Personal Projects\n\n- [FYGT](https://github.com/DerekCuevas/derekcuevas.github.io): An experimental blog built with `Hugo`, `Deno`, and `ChatGPT`.\n- [Advent of Code 2022](https://github.com/DerekCuevas/advent-of-code-2022): Solutions to Advent of Code programming problems using functional approaches in `Clojure`.\n- [Interview Cake Algorithms Problem Set](https://github.com/DerekCuevas/interview-cake-clj): Solutions to the interview cake programming problems also by exploring functional approaches in `Clojure`.\n- [Friend List](https://github.com/DerekCuevas/friend-list): A non-trivial programming challenge exploring asynchronous side effects with different programming patterns.\n- [Redux Meta Reducer](https://github.com/DerekCuevas/redux-meta-reducer): A `Redux` higher-order reducer for simplifying the state of fetched data.\n- [Avowal](https://github.com/DerekCuevas/avowal): An asynchronous form validation library for `JavaScript`.\n"
  },
  {
   "role": "system",
   "content": "New topics for the blog should be based off of the technical skills, experience, and interests presented in the resume."
  },
  {
   "role": "system",
   "content": "Your previous 40 posts include: \"Advanced Techniques for Debugging Rust Programs\", \"Writing a Domain-Specific Language (DSL) in Haskell\", \"Securely Managing Secrets in Production Applications\", \"Implementing the Factory Method Design Pattern in Dart\", \"Boosting Rust Performance with Allocator Selection\", \"Building Real-Time Audio Applications with WebRTC and Rust\", \"Rust's Pinning API: A Comprehensive Guide\", \"Building a Highly Scalable and Fault-Tolerant Load Balancer with Rust\", \"How to Use AWS Fargate for Highly Scalable and Serverless Containers\", \"How to Build a Recommendation Engine with Apache Spark\", \"Building a Distributed Key-Value Store on Top of Apache Kafka\", \"Building a GraphQL API with Actix-Web and Diesel\", \"Building a High-Performance HTTP Proxy with Nginx\", \"How to Use Kafka to Build Scalable and Fault-Tolerant Distributed Systems\", \"Advanced Techniques for Using PostgreSQL JSONB Data Type\", \"Writing Secure Rust Code: A Deep Dive into Memory Safety\", \"Fine-tuning BERT for Question Answering - A Step-by-Step Guide\", \"How to Use the Decorator Pattern for Flexible and Extensible Code\", \"A Deep Dive into Multithreading with Clojure\", \"How to Design Reactive Microservices Using Event-Driven Architecture\", \"Writing Efficient SQL Queries: Tips and Tricks\", \"Mastering Connection Pooling in Django\", \"Mastering the Actor Model Concurrency Paradigm in Elixir\", \"How to use Elm to build maintainable, efficient, and bug-free front-end applications\", \"How to Use Generators to Create Infinite Sequences in Python\", \"Building High Performance Distributed Data Pipelines with Apache Flink\", \"Implementing a Consistent Hashing Algorithm in TypeScript\", \"The Event Sourcing Design Pattern in TypeScript\", \"How to Write Fast Python Code\", \"Building a High-Availability Microservice Architecture with Modern C++\", \"How to Build a Realtime Collaborative Spreadsheet Application with Elixir and Phoenix LiveView\", \"Using the Adapter Pattern to Integrate Legacy Code\", \"Building a Highly Scalable and Performant GraphQL API with Sangria\", \"Building Robust Elixir Back-End APIs with Phoenix Contexts\", \"Building real-time collaborative web apps with Operational Transformation\", \"Mastering Rust's Standard Library Function `mem::forget()`\", \"Build a Scalable, Maintainable, and Performant Full-Text Search System for Your Application with Elasticsearch\", \"Mastering Clojure's Reducers\", \"How to Use Swift's Result Type for Error Handling\", \"Mastering Rust Ownership Rules and Borrowing Rules for Type-Safe and Performant Programs\""
  },
  {
   "role": "system",
   "content": "Your writing style is concise, to the point, informative, and focused on detailed technical information."
  },
  {
   "role": "user",
   "content": "Come up with an advanced topic for an expert level reader that is about a particular single feature, fact, pattern, paradigm, convention, theory, framework, library, or best practice."
  },
  {
   "role": "user",
   "content": "The topic should not be related to a previous post."
  },
  {
   "role": "user",
   "content": "Write a post about the topic following the rules defined."
  },
  {
   "role": "user",
   "content": "Use computer code snippets (in the relevant programming language) in order to illustrate the information presented."
  },
  {
   "role": "user",
   "content": "Format the body of the post in the markdown markup language."
  },
  {
   "role": "user",
   "content": "Include the title of the post on the first line."
  },
  {
   "role": "user",
   "content": "Include one to three tags for the post on the second line formatted as a comma separated list, for example: \"Tags: <tag1>, <tag2>\"."
  },
  {
   "role": "user",
   "content": "Do not include or link to images in the post."
  },
  {
   "role": "user",
   "content": "The post should be multiple sections in length and come to a complete finish."
  }
 ],
 "completion": {
  "id": "chatcmpl-7QrO2qa2T5YMF5nNmJnRRG2ZSPs3o",
  "object": "chat.completion",
  "created": 1686636102,
  "model": "gpt-3.5-turbo-0301",
  "usage": {
   "prompt_tokens": 2062,
   "completion_tokens": 1089,
   "total_tokens": 3151
  },
  "choices": [
   {
    "message": {
     "role": "assistant",
     "content": "### Title: Using Array Partitions in Python for Improved Performance\n\nTags: Python, Performance\n\nArray partitions are a powerful tool to improve performance in Python applications. They allow you to divide big arrays into smaller pieces, operating on each piece independently. This approach can be used in a range of applications, from data processing to numerical simulations and machine learning.\n\nIn this post, we'll take a deep dive into the array partitioning technique, see how it can be used to optimize performance, and learn how to implement array partitioning in Python.\n\n## What are Array Partitions?\n\nArray partitioning is the process of dividing an array into smaller sub-arrays, or partitions to better utilize available computational resources. This approach is especially useful when working with large data sets that can occupy significant portions of the memory, as processing only a portion at a time can prevent the operating system from having to use virtual memory to compensate for memory limitations.\n\nArray partitioning can be applied to both one-dimensional and multi-dimensional arrays. For example, you might partition a one-dimensional array into several smaller chunks, or partition a two-dimensional array along either the row or column axis, or both.\n\nOnce the partitions are created, we can apply multi-core CPU parallelism to operate on each partition independently, which significantly speeds up computation time.\n\n## How to Implement Array Partitioning in Python\n\nIn Python, there are several ways to implement array partitioning. One of the simplest methods is to use the `numpy.array_split()` method to partition a numpy array into equally sized partitions. \n\n```python\nimport numpy as np\n\n# create 1D array\narr = np.arange(10)\n\nprint(\"Original array: \\n\", arr)\n\n# partition array into chunks of size 3\npartitions = np.array_split(arr, 3)\n\n# print partitions\nfor i, p in enumerate(partitions):\n    print(f\"Partition {i}: {p}\")\n```\n\nOutput:\n```\nOriginal array:\n [0 1 2 3 4 5 6 7 8 9]\nPartition 0: [0 1 2 3]\nPartition 1: [4 5 6]\nPartition 2: [7 8 9]\n```\n\nIn this example, we created a one-dimensional numpy array and used the `numpy.array_split()` method to partition the array into 3 partitions. We then looped through each partition and printed the partition contents.\n\nWe can also partition multi-dimensional arrays in a similar way. For example, to partition a 2D-array column-wise, we can use the `numpy.hsplit()` method:\n\n```python\n# create 2D array\narr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# partition array along the column axis\npartitions = np.hsplit(arr_2d, 3)\n\n# print partitions\nfor i, p in enumerate(partitions):\n    print(f\"Partition {i}: \\n {p}\")\n```\n\nOutput:\n```\nPartition 0:\n [[1]\n [4]\n [7]]\nPartition 1:\n [[2]\n [5]\n [8]]\nPartition 2:\n [[3]\n [6]\n [9]]\n```\n\nIn this example, we partitioned a two-dimensional array along the column axis by using the `numpy.hsplit()` method. We then printed each partition separately.\n\n## How to Use Array Partitions to Improve Performance\n\nNow that we know how to partition arrays in Python, let's see how we can use partitioning to improve our code's performance.\n\nAssuming we have a time-consuming computation, we can partition our data and use multi-core parallelism to process each part independently. In this way, we can distribute computation over several cores and reduce total computation time. \n\nHere's an example of how we can use array partitioning to calculate the sum of a 2D numpy array:\n\n```python\nimport time\n\n# create a large 2D array\nlarge_arr = np.random.randn(10_000, 10_000)\n\n# split the array in half\npartitions = np.split(large_arr, 2)\n\n# sum each partition in parallel\nsums = []\nfor p in partitions:\n    start = time.time()\n    result = np.sum(p)\n    sums.append(result)\n    end = time.time()\n    print(f\"Partition processed in {end - start:.5f} seconds\")\n\n# combine results\nresult = np.sum(sums)\n```\n\nIn this example, we created a large two-dimensional numpy array, and partitioned it into two sub-arrays. We then used a `for` loop to sequentially sum each partition. Using multi-core CPU parallelism could be an option via any multiprocessing, concurrent.futures or dask. \n\nBy utilizing partitioning and parallelism, the total sum can be computed much faster than when the entire array is processed in one go.\n\n## Conclusion\n\nArray partitioning is a powerful performance optimization technique for any Python application that deals with large arrays or datasets. With array partitioning, we can divide up a larger dataset into smaller partitions, use each partition in parallel, and reduce computation time. In this post, we learned how to implement array partitioning in Python and how to use partitioning to improve performance."
    },
    "finish_reason": "stop",
    "index": 0
   }
  ]
 }
}