{
 "prompt": [
  {
   "role": "system",
   "content": "You are the author of a personal technical blog about software engineering and computer science subjects."
  },
  {
   "role": "system",
   "content": "Write as though you are the author of this resume:\n+++\ntitle = \"Résumé\"\ndescription = \"Derek Cuevas' Résumé\"\ndate = \"2023-05-20\"\nor = \"Derek Cuevas\"\n+++\n\nHi, my name is [Derek Cuevas](https://github.com/derekcuevas), I'm a Senior Software Engineer with 8 years of professional experience, currently working at [Second Spectrum](https://www.secondspectrum.com/) where I lead a systems software engineering team building low latency and realtime Emmy award winning products for live TV broadcasters leveraging the [Rust](https://www.rust-lang.org/) programming language.\n\nIn the past, I've built and worked on full stack web and mobile applications, leveraging technologies such as `TypeScript`, `Node.js`, `React`, and `Swift`, as well as worked on performance critical and highly available backend systems and services. \n\n\n---\n\n# Programming Languages\n\n- `Proficient:` Rust, TypeScript (& JavaScript) \n- `Experienced:` Clojure, Elm, Swift, Elixir, SQL\n\n# Technologies, Skills, and Interests\n\n- `Rust:` Tokio, Futures, Hyper, Actix, Warp \n- `Platforms and Services:` AWS, Docker, PostgreSQL, Redis, Apache Pulsar, RabbitMQ, Node.js, Deno, HTML & CSS\n- `Tooling:` Git, Vim, Bash\n- `Frameworks:` React, React Native, Redux, RxJs, SwiftUI\n- `Protocols:` HTTP, GraphQL, WebSockets, ØMQ, JSON, MessagePack, Protobuf, FlatBuffers\n- `Paradigms:` Functional Programming, Realtime Systems\n\n---\n\n# Professional Experience\n\n## Senior Software Engineer II (Lead), Second Spectrum\n(*January 2021 - Current*)\n\nAcquired by Genius Sports [https://geniussports.com/](https://geniussports.com/)\n\n- Technical lead for the \"Realtime Augmentation Engine\" project's system team. The project is developed for live TV broadcasters of sporting events and combines a unique machine understanding of the game (through live player tracking data, computer vision, and automated eventing algorithms) with a 3D graphics engine to provide low-latency and realtime virtual-reality like experiences to broadcasters.\n- The project is a multiple times winner at the `Sports Emmys` awards. Most notably the winner of the prestigious [George Wensel Technical Achievement Award](https://geniussports.com/customer-stories/cbs-and-genius-win-sports-emmy-for-romovision/) in partnership with CBS for `\"RomoVision\"` at the 43rd awards. Also helped to secure Amazon's Emmy for [Outstanding Interactive Experience](https://www.aboutamazon.com/news/entertainment/thursday-night-football-on-prime-video-wins-sports-emmy-award) at the 44th annual awards for `TNF \"PrimeVision\"`.\n- Other notable executions powered by this project include [Marvel Arena of Heros](https://www.marvel.com/articles/culture-lifestyle/marvel-arena-of-heroes-golden-state-warriors-new-orleans-pelicans), [Clippers CourtVision](https://www.clipperscourtvision.com/), and [Premier League Data Zone](https://worldsoccertalk.com/peacock-adds-premier-league-data-zone-as-new-feature-20230406-WST-427164.html).\n- TODO: (be more specific with tech involved, provide real metrics) As the technical lead, I oversaw development and integrations for the core systems as well as the automated operational management and monitoring systems, release management, and led efforts to profile and optimize the system for the lowest possible latency. Video and data ingestion. Developed framework for algorithms integration.\n\n## Senior Software Engineer I (Lead), Second Spectrum\n(*January 2019 - January 2021*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Developed an application that allowed for searching for and visualizing discrepancies between different player tracking datasets. The application proved vital in proving the accuracy of our player tracking system to leagues and sporting teams by highlighting how use of different tracking anchor points (such as a player's \"center of mass\" projected to the ground vs a players feet location) could effect derived metrics such as a player's speed or total distance traveled.\n- Led a team of three engineers developed the companies first GraphQL server \n- Successfully mentored several interns and fellow engineers. Cultivated environment for team growth, collaboration, and knowledge sharing. Led pair programming sessions, code reviews, and learning groups discussions (FP, Rust, GraphQL).\n- TODO: Data Graph, Players Only, Output Page \n\n## Software Engineer, Second Spectrum\n(*August 2016 - January 2019*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Developed the operational and quality assurance management application for the companies optical player tracking system.\n- Developed an automated QA task selection system, conducted A/B tests, and improved overall operator efficiency by 100%.\n- Gained experience building applications that displayed large amounts of frequently updated real-time data. Leveraged React, Redux, and Phoenix (Elixir) as the primary frameworks in addition to heavy use of Web Sockets.\n- TODO: Redstone, Clippers CourtVision, CourtVision Mobile, Silverware, Falcon\n\n## Software Engineer Intern, MindGraph Medical\n(*September 2015 - January 2016*)\n\n- Designed, developed, and deployed the MindGraph Medical website. Deployed onto `AWS` and built using `Node.js`, `Jquery`, and `Bootstrap`.\n\n---\n\n# Education\n**B.S. Computer Science, San Diego State University, San Diego**\n\n(*Class of 2016*)\n\n- Computer Science GPA: `3.81`\n- [Advanced Certificate in Web and Mobile Applications Development](https://cs.sdsu.edu/about/)\n\n---\n\n# Personal Projects\n\nFor fun, I like solving programming problems and puzzles and have completed many of the [Advent of Code](https://adventofcode.com/) problems (and similar problem sets) by exploring `functional` approaches in the [Clojure](https://clojure.org/) programming language. Some of my solutions can be found on GitHub: \n\n- [Advent of Code 2022](https://github.com/DerekCuevas/advent-of-code-2022)\n- [Advent of Code 2015](https://github.com/DerekCuevas/advent-of-code-2015)\n- [Interview Cake Algorithms Problem Set](https://github.com/DerekCuevas/interview-cake-clj)\n\nSome of my other past personal projects include:\n\n- [\"Friend List\" Programming Challenge](https://github.com/DerekCuevas/friend-list): A non-trivial example programming challenge that explores the modeling of asynchronous side effects with different programming patterns.\n- [Redux Meta Reducer](https://github.com/DerekCuevas/redux-meta-reducer): A Redux higher order reducer to help simplify the state of fetched data.\n- [Avowal](https://github.com/DerekCuevas/avowal): An asynchronous form validation library for JavaScript.\n"
  },
  {
   "role": "system",
   "content": "New topics for the blog should be based off of the technical skills, experience, and interests presented in the resume."
  },
  {
   "role": "system",
   "content": "Your previous 20 posts include: \"Mastering Clojure's Reducers\", \"How to Use Swift's Result Type for Error Handling\", \"Mastering Rust Ownership Rules and Borrowing Rules for Type-Safe and Performant Programs\", \"Projecting Elixir's Enum Module into Batches\", \"Mastering Browser Storage in TypeScript\", \"Mastering Rust's `std::env::args_os()`\", \"Building Composable, Scalable, and Reusable Redux Reducers\", \"Exploring Rust's `mem::replace()` Function\", \"Advanced TypeScript: Custom Type Guards\", \"Mastering Elixir's GenServer Callbacks\", \"The Magic of High-Level Streams\", \"Using Rust's Pinning API for Safe and Performant Async Programming\", \"Building Scalable REST APIs with Node.js and PostgreSQL\", \"How to Build High-Availability WebSocket Services with Rust and Actix-Web\", \"A Practical Introduction to the Actor Model in Elixir\", \"Mastering JavaScript's Array.concat() Method for High-Performance and Scalable Code\", \"Building High-Performance, Real-time Message-Based Applications with Rust and Pulsar\", \"The Art of Error Handling in Node.js\", \"JSON Data Validation with Rust's `serde_json` Library\", \"Exploring the Rust Standard Library's VecDeque\""
  },
  {
   "role": "system",
   "content": "Your writing style is concise, to the point, informative, and focused on detailed technical information."
  },
  {
   "role": "user",
   "content": "Come up with an advanced topic for an expert level reader that is about a particular single feature, fact, pattern, paradigm, convention, theory, framework, library, practical example, or best practice."
  },
  {
   "role": "user",
   "content": "The topic should not be related to a previous post."
  },
  {
   "role": "user",
   "content": "Write a post about the topic following the rules defined."
  },
  {
   "role": "user",
   "content": "Use computer code snippets (in the relevant programming language) in order to illustrate the information presented."
  },
  {
   "role": "user",
   "content": "Format the body of the post in the markdown markup language."
  },
  {
   "role": "user",
   "content": "Include the title of the post on the first line."
  },
  {
   "role": "user",
   "content": "Include one to three tags for the post on the second line formatted as a comma separated list, for example: \"Tags: <tag1>, <tag2>\"."
  },
  {
   "role": "user",
   "content": "Do not include images in the post."
  },
  {
   "role": "user",
   "content": "The post should be multiple sections in length and come to a complete finish."
  }
 ],
 "completion": {
  "id": "chatcmpl-7NlNwqk65cMyQM4IwgTk06GjruczI",
  "object": "chat.completion",
  "created": 1685898048,
  "model": "gpt-3.5-turbo-0301",
  "usage": {
   "prompt_tokens": 2041,
   "completion_tokens": 1305,
   "total_tokens": 3346
  },
  "choices": [
   {
    "message": {
     "role": "assistant",
     "content": "Build a Scalable, Maintainable, and Performant Full-Text Search System for Your Application with Elasticsearch\n\nTags: Elasticsearch, Full-Text Search, Distributed System\n\nIf you’re building an application with a lot of text-based content such as articles, comments, user-profiles, messages, or product information, using a full-text search engine is an excellent way to provide an advanced search functionality for your users. Elasticsearch is a popular, distributed, and highly scalable search engine based on the Apache Lucene library that allows for complex search queries and real-time indexing and search. In this article, we’ll show you how to build a scalable, maintainable, and performant search system for your application using Elasticsearch.\n\n## Why Elasticsearch?\n\nThere are many benefits to using Elasticsearch for full-text search in your application. Some of these benefits include:\n\n- **Scalability**: Elasticsearch is distributed by nature, so it’s easy to scale horizontally as your data grows.\n- **Real-time indexing and search**: Elasticsearch allows for near-instant indexing and search of new documents.\n- **Full-text search**: Elasticsearch easily handles large amounts of text-based content, and provides advanced full-text search capabilities such as fuzzy search, phrase search, proximity search, etc.\n- **Aggregation and analytics**: Elasticsearch provides powerful aggregation and analytics capabilities, so you can use it for more than just search.\n\n## Setting up Elasticsearch\n\nBefore we dive into the details of how to use Elasticsearch in your application, let’s first cover how to set it up. Elasticsearch can be run on-premises or in the cloud, but for the purpose of this article, we’ll show you how to set up a single Elasticsearch instance locally. \n\nHere are the steps to do that:\n\n1. Download Elasticsearch from the official download page - [https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch).\n2. Extract the downloaded package to a directory of your choice.\n3. Navigate to the Elasticsearch bin directory and start Elasticsearch by running the following command: \n```bash\n./elasticsearch\n```\n4. Verify that Elasticsearch has started successfully by opening a web browser and navigating to [http://localhost:9200/](http://localhost:9200/). You should see a response like this:\n```json\n{\n  \"name\" : \"your-elasticsearch-instance-name\",\n  \"cluster_name\" : \"elasticsearch\",\n  \"cluster_uuid\" : \"random-uuid-here\",\n  \"version\" : {\n    \"number\" : \"7.10.0\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"tar\",\n    \"build_hash\" : \"51e9d6f22758d0374a0f3f5c6e8f3a799a5dbdb\",\n    \"build_date\" : \"2020-11-09T21:30:33.964949Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.7.0\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n```\n\n## Indexing Data\n\nOnce you have Elasticsearch set up, the next step is to index your data. In Elasticsearch, data is organized into indices, which are essentially logical collections of documents with similar properties. An index can be thought of as a database table in a relational database.\n\nTo create an index, you can use Elasticsearch’s REST API, which allows you to perform various actions on Elasticsearch using HTTP requests. Here’s an example of how to create an index called `my_index`:\n\n```bash\ncurl -X PUT \"localhost:9200/my_index?pretty\"\n```\n\nOnce you have an index, you can start adding documents to it. A document is a basic unit of information in Elasticsearch, and is similar to a row in a database table. Here’s an example of how to add a document to the `my_index` index:\n\n```bash\ncurl -X PUT \"localhost:9200/my_index/_doc/1?pretty\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"title\": \"My Document Title\", \"body\": \"This is the body of my document.\"}'\n```\n\nThis will add a new document to the `my_index` index with an ID of `1`. You can add more documents to the index by changing the ID.\n\n## Searching Data\n\nNow that we have data indexed in Elasticsearch, we can start searching it. Elasticsearch provides a powerful search API that allows for complex queries and filtering.\n\nHere’s an example of a simple search query that searches the `my_index` index for documents that contain the word `body` in the `title` field:\n\n```bash\ncurl -X GET \"localhost:9200/my_index/_search?q=title:body&pretty\"\n```\n\nThis will return a JSON response with information about the matching documents.\n\n### Query DSL\n\nElasticsearch’s search API also supports a powerful Query DSL (Domain Specific Language) that allows for more complex queries and filtering. Here’s an example of how to search the `my_index` index for documents that contain the word `body` in the `title` field or the `body` field, and return only the `title` field in the response:\n\n```bash\ncurl -X GET \"localhost:9200/my_index/_search?pretty\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"query\": {\n               \"multi_match\" : {\n                   \"query\" : \"body\",\n                   \"fields\" : [\"title\", \"body\"]\n               }\n           },\n           \"_source\": [\"title\"]\n         }'\n```\n\nThis will return a JSON response with only the `title` field for matching documents.\n\n## Conclusion\n\nElasticsearch provides a powerful, scalable, and feature-rich search engine that is ideal for full-text search in applications. In this article, we’ve shown you how to set up Elasticsearch, index data, and search data using Elasticsearch’s REST API and Query DSL. With Elasticsearch, you can build a robust search system for your application that provides real-time indexing and search, advanced query capabilities, and scalability as your data grows."
    },
    "finish_reason": "stop",
    "index": 0
   }
  ]
 }
}