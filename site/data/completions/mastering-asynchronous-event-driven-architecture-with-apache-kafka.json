{
 "model": "gpt-3.5-turbo-0301",
 "prompt": [
  {
   "role": "user",
   "content": "You are the author of a personal technical blog about software engineering and computer science subjects."
  },
  {
   "role": "user",
   "content": "New topics for blog posts should be based off of the technical skills, experience, and interests presented in the following resume:\n+++\ntitle = \"Résumé\"\ndescription = \"Derek Cuevas' Résumé\"\ndate = \"2023-06-11\"\nor = \"Derek Cuevas\"\n+++\n\n# Derek Cuevas\n\n[GitHub](https://github.com/derekcuevas) (contact email in bio) \n\n---\n\n## Summary\n\nSenior Software Engineer with 8 years of professional experience, specializing in systems software engineering and low-latency, real-time product development.\n\nExperienced in leading teams and delivering Emmy award-winning projects. Passionate about functional programming and building high performance real-time systems. Skilled in a variety of programming languages and technologies with expertise in [Rust](https://www.rust-lang.org/) and [TypeScript](https://www.typescriptlang.org/).\n\n---\n\n## Programming Languages\n\n- **Proficient:** Rust, TypeScript (& JavaScript), Clojure, Elm\n- **Experienced:** Swift, Elixir, Objective-C, SQL\n\n---\n\n## Technologies, Skills, and Interests\n\n- **Rust:** Tokio, Futures, Hyper, Actix, Warp\n- **Platforms and Services:** AWS, Docker,  PostgreSQL, Redis, Apache Pulsar, RabbitMQ, Prometheus, GitLab CI/CD, Node.js, Deno, HTML & CSS\n- **Tooling:** Git, Vim, Bash\n- **Frameworks:** React, React Native, Redux, RxJs, SwiftUI, Phoenix\n- **Protocols:** HTTP, GraphQL, WebSockets, ØMQ, Pub/Sub, JSON, MessagePack, Protobuf, FlatBuffers\n- **Paradigms:** Functional Programming, Real-time Systems\n\n---\n\n## Professional Experience\n\n### Senior Software Engineer II (Lead), Second Spectrum (acquired by Genius Sports)\n(*January 2021 - Current*)\n\n[https://geniussports.com/](https://geniussports.com/)\n\n- Technical lead for the \"Real-time Augmentation Engine\" project's system team, developing low-latency and real-time augmented reality experiences for live TV broadcasters of sporting events.\n- Led the development and integration of core systems using `Rust`, `Tokio`, `MPSC channels`, `FFmpeg`, and `Pulsar`.\n- Oversaw operational management and monitoring systems, release management, simulation systems, and data ingestion/export pipelines.\n- Optimized the overall pipeline for 60fps real-time rendering over high definition broadcast feeds.\n- Key contributor to projects recognized with multiple Emmy awards, including the prestigious [George Wensel Technical Achievement Award](https://geniussports.com/customer-stories/cbs-and-genius-win-sports-emmy-for-romovision/) and Amazon's [Outstanding Interactive Experience](https://www.aboutamazon.com/news/entertainment/thursday-night-football-on-prime-video-wins-sports-emmy-award) at the `Sports Emmys`.\n\n### Senior Software Engineer I (Lead), Second Spectrum\n(*January 2019 - January 2021*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Led a team in designing and developing the company's first `GraphQL` service serving as a unified gateway for various microservices. Built upon the `Apollo` server framework leveraging `Node.js`, `TypeScript`, `PostgreSQL`, and `Redis` for caching and pub/sub.\n- Developed a dashboard built with `Three.js` for visualizing 3D player tracking datasets and highlighting data discrepancies.\n- Created a prototype `iOS` application for video highlights using `Swift`, `SwiftUI`, and the `Combine` framework.\n- Mentored interns and fellow engineers, fostering collaboration and knowledge sharing.\n\n### Software Engineer, Second Spectrum\n(*August 2016 - January 2019*)\n\n[https://www.secondspectrum.com/](https://www.secondspectrum.com/)\n\n- Developed the operational and quality assurance management application for the company's optical player tracking system. Stack included `Elixir` (with the `Phoenix` framework), `React`, and heavy use of `WebSockets` to sync and display corrections to operators in near real-time.\n- Improved operator efficiency by 100% through the implementation of an automated task selection system.\n- Led the development of the LA Clipper's live streaming web and mobile application \"Clippers CourtVision\". Stack included `Elm` for the web front-end and `React Native` for the mobile app.\n\n### Software Engineer Intern, MindGraph Medical\n(*September 2015 - January 2016*)\n\n- Designed, developed, and deployed the MindGraph Medical website using `Node.js`, `jQuery`, and `Bootstrap`.\n\n---\n\n## Education\n\n**B.S. Computer Science, San Diego State University, San Diego**\n\n(*Class of 2016*)\n\n- [Advanced Certificate in Web and Mobile Applications Development](https://cs.sdsu.edu/about/)\n\n---\n\n## Personal Projects\n\n- [FYGT](https://github.com/DerekCuevas/derekcuevas.github.io): An experimental blog built with `Hugo`, `Deno`, and `ChatGPT`.\n- [Advent of Code 2022](https://github.com/DerekCuevas/advent-of-code-2022): Solutions to Advent of Code programming problems using functional approaches in `Clojure`.\n- [Interview Cake Algorithms Problem Set](https://github.com/DerekCuevas/interview-cake-clj): Solutions to the interview cake programming problems also by exploring functional approaches in `Clojure`.\n- [Friend List](https://github.com/DerekCuevas/friend-list): A non-trivial programming challenge exploring asynchronous side effects with different programming patterns.\n- [Redux Meta Reducer](https://github.com/DerekCuevas/redux-meta-reducer): A `Redux` higher-order reducer for simplifying the state of fetched data.\n- [Avowal](https://github.com/DerekCuevas/avowal): An asynchronous form validation library for `JavaScript`.\n"
  },
  {
   "role": "user",
   "content": "Your previous 60 posts include: \"Advanced Techniques for Distributed System Design using Apache Cassandra\", \"Exploring the Underlying Architecture of TypeScript\", \"Functional Reactive Programming with Elm: A Comprehensive Guide\", \"Exploring the Power of Clojure's Persistent Data Structures\", \"The Power of Rust's Multithreading Library: rayon\", \"The Power of the `async` Keyword in Rust: A Comprehensive Guide\", \"Mastering Cache Invalidation Strategies: A Comprehensive Guide\", \"Mastering Rust's Serialization and Deserialization: A Comprehensive Guide\", \"Mastering AWS S3 for High Availability: A Comprehensive Guide\", \"Exploring the Fundamentals of Reactive Programming\", \"Mastering Rust's Pinning: An Advanced Guide\", \"Understanding Higher Order Functions in TypeScript\", \"Mastering Async/Await in TypeScript: A Comprehensive Guide\", \"Building High Availability Systems with Apache ZooKeeper\", \"Mastering Rust's Unsafe Keyword: A Comprehensive Guide\", \"The Power of Immutable Data Structures in JavaScript\", \"Building a Highly Available System with Apache ZooKeeper\", \"Mastering Persistent Connections in Java\", \"Mastering Real-Time Communication with WebSockets in Elixir\", \"Understanding the Reactive Stream Pattern\", \"Understanding the Power of Rust's Macros\", \"Mastering Rust's Futures: An Advanced Guide\", \"Advanced Techniques for Working with Rust's Borrow Checker\", \"Understanding the Difference Between Block and Inline Elements in HTML\", \"Mastering Kafka Connect: A Comprehensive Guide\", \"Effective Error Handling in Swift: Best Practices and Patterns\", \"The Power of Kotlin's Coroutines: A Comprehensive Guide\", \"Mastering Asynchronous Programming in Rust: A Comprehensive Guide\", \"Building Custom Collectors in Java: A Comprehensive Guide\", \"The Art of Domain-Driven Design\", \"Exploring the Power of React's Context API: A Comprehensive Guide\", \"Mastering the Observer Pattern with Swift\", \"Mastering the Actor Model with Elixir\", \"Mastering Rust's Memory Safety Paradigm\", \"Mastering Quicksort Algorithm in Clojure\", \"Mastering the Builder Design Pattern in Java\", \"Building Resilient Distributed Systems with Flink\", \"Building Real-Time Applications with Go Channels\", \"Mastering Zero-Knowledge Proofs: A Comprehensive Guide\", \"The Power of Ruby's Metaprogramming Techniques\", \"Beyond the Basics of React Performance: Advanced Techniques for Optimizing your Application\", \"Mastering Zero-Copy I/O in Rust\", \"Mastering GraphQL Subscriptions with Rust\", \"Mastering Git's Interactive Rebase: A Comprehensive Guide\", \"Exploring the Power of Rust’s Generic Associated Types\", \"Mastering WebAssembly Text Format – A Comprehensive Guide\", \"Building Robust and Secure GraphQL Servers with Rust\", \"Mastering Debugging Techniques in Rust: A Comprehensive Guide\", \"Implementing a Consistent Hashing Algorithm in Rust\", \"Understanding Protocol Buffers Wire Format: A Comprehensive Guide\", \"Understanding Tail-Recursion in Elixir\", \"Exploring Kubernetes StatefulSets: A Comprehensive Guide\", \"The Science of Machine Learning: Explaining the Bias-Variance Tradeoff\", \"Mastering Advanced Feature-Driven Development: A Comprehensive Guide\", \"Mastering the Elm Architecture: A Comprehensive Guide\", \"Exploring the Rust Standard Library's `net` Module\", \"Understanding the Rust Trait System: A Comprehensive Guide\", \"Mastering Rust's Concurrency Primitives: A Comprehensive Guide\", \"Building High-Performance Microservices with Rust's Actix-Web Framework\", \"Advanced Techniques for Building Serverless Applications with AWS Lambda\""
  },
  {
   "role": "user",
   "content": "Come up with an advanced topic for an expert level reader that is about a particular single feature, fact, pattern, paradigm, convention, theory, framework, library, or best practice."
  },
  {
   "role": "user",
   "content": "Write a post about the chosen topic following the instructions given below:"
  },
  {
   "role": "user",
   "content": "Your writing style is academic, informative, and focused on detailed technical information."
  },
  {
   "role": "user",
   "content": "The topic should not be related to a previous post."
  },
  {
   "role": "user",
   "content": "Use computer code snippets (in the relevant programming language) in order to illustrate the information presented."
  },
  {
   "role": "user",
   "content": "Format the body of the post in the markdown markup language."
  },
  {
   "role": "user",
   "content": "Come up with a title for the post and include it on the first line."
  },
  {
   "role": "user",
   "content": "Include one to three tags for the post on the second line formatted as a comma separated list, for example: \"Tags: <tag1>, <tag2>\"."
  },
  {
   "role": "user",
   "content": "The post should be multiple sections in length."
  },
  {
   "role": "user",
   "content": "Do not include links to images in the post."
  },
  {
   "role": "user",
   "content": "Do not include contact information in the post."
  },
  {
   "role": "user",
   "content": "Do not add extra whitespace around lists."
  }
 ],
 "completion": {
  "id": "chatcmpl-7qAPkNgAyd2lruLrxSQ96cwcGaXA1",
  "object": "chat.completion",
  "created": 1692667444,
  "model": "gpt-3.5-turbo-0301",
  "choices": [
   {
    "index": 0,
    "message": {
     "role": "assistant",
     "content": "Title: Mastering Asynchronous Event-Driven Architecture with Apache Kafka\n\nTags: Kafka, Event-Driven Architecture, Asynchronous Programming\n\n---\n\nEvent-Driven Architecture (EDA) has become increasingly popular in modern software systems. By decoupling components and services, EDA allows for building systems that are scalable and resilient. Apache Kafka has become the de-facto standard for distributed event streaming architectures. In this post, we will discuss the key concepts of EDA as well as dive deep into how to use Kafka as the foundation for building an event-driven architecture. \n\n## Understanding Event-Driven Architecture\n\nEDA is a software architecture that enables building loosely coupled, scalable, and resilient systems that can react in real-time to changes. The idea is to have components that interact with each other by producing and consuming events. An event represents a change in state or a significant occurrence in the system. Examples of events include a user logging in, a product being added to a cart, or a sensor detecting a change in temperature.\n\nWhen an event occurs, the component that produces the event publishes it to a message broker. A message broker is an application that receives and stores events and delivers them to the components that are interested in consuming them. Components that consume events are called subscribers. Subscribers receive events through a subscription mechanism and act on them. The key advantage of EDA is that it enables a loosely coupled and scalable architecture, where each component is responsible for its own functionality and reacts to other components' state changes through the events produced.\n\n## Apache Kafka\n\nApache Kafka is an open-source distributed event streaming platform that provides persistent, fault-tolerant brokers to store and transmit event stream data. Kafka follows the publish-subscribe model of EDA. Messages in Kafka are organized into topics, and a topic consists of one or more partitions. Each partition can be replicated across multiple brokers for fault tolerance.\n\nThe Kafka ecosystem consists of several components, including producers, consumers, and streaming applications. Producers are responsible for publishing events to Kafka topics, while consumers subscribe to topics and process the events. Streaming applications process and transform streams of events in real-time.\n\nA key feature of Kafka is its ability to provide low latency, high throughput, and scalability while maintaining data durability. Kafka achieves this through its distributed design, built-in fault tolerance, and its ability to handle large data volumes.\n\n## Building an Event-Driven Architecture with Apache Kafka\n\nTo build an event-driven architecture with Kafka, we need to design our architecture around events. That involves identifying the events that our components will produce and consume and designing our Kafka topics and partitions accordingly. We also need to choose the appropriate Kafka components to handle our event streams, such as Kafka Producers, Kafka Consumers, and Kafka Streams APIs.\n\nTo create a Kafka topic, we can use the Kafka command-line utility or the Kafka API. Here is an example in Python using the `kafka-python` library:\n\n```python\nfrom kafka.admin import KafkaAdminClient, NewTopic\n\nadmin_client = KafkaAdminClient(bootstrap_servers='localhost:9092')\ntopic_list = []\ntopic_list.append(NewTopic(name='my-topic', num_partitions=3, replication_factor=1))\nadmin_client.create_topics(new_topics=topic_list, validate_only=False)\n\n```\n\nIn this example, we create a Kafka topic called 'my-topic', with three partitions and a replication factor of 1. \n\nTo produce events to a Kafka topic, we can use a Kafka Producer. Here's an example in Java using the Kafka Producer API:\n\n```java\nimport org.apache.kafka.clients.producer.*;\nimport java.util.Properties;\n\npublic class KafkaProducerExample {\n     public static void main(String[] args) {\n         Properties props = new Properties();\n         props.setProperty(\"bootstrap.servers\", \"localhost:9092\");\n         props.setProperty(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n         props.setProperty(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n         Producer<String, String> producer = new KafkaProducer<>(props);\n         for (int i = 0; i < 10; i++)\n             producer.send(new ProducerRecord<>(\"my-topic\", \"value-\" + i));\n         producer.close();\n     }\n}\n```\n\nIn this example, we create a KafkaProducer that publishes ten events to the 'my-topic' topic with String key and value serializers.\n\nTo consume events from a Kafka topic, we can use a Kafka Consumer. Here's an example in Node.js, using the `kafkajs` library:\n\n```javascript\nconst { Kafka } = require('kafkajs')\n\nconst kafka = new Kafka({\n  clientId: 'my-app',\n  brokers: ['localhost:9092']\n})\n\nconst consumer = kafka.consumer({ groupId: 'my-group' })\n\nconst run = async () => {\n  await consumer.connect()\n  await consumer.subscribe({ topic: 'my-topic', fromBeginning: true })\n\n  await consumer.run({\n    eachMessage: async ({ topic, partition, message }) => {\n      console.log({\n        value: message.value.toString(),\n      })\n    },\n  })\n}\n\nrun().catch(console.error)\n```\n\nIn this example, we create a Kafka Consumer that subscribes to the 'my-topic' topic, consuming events using an `eachMessage` handler.\n\n## Conclusion\n\nEDA is a powerful architecture that enables building scalable, resilient, and loosely coupled systems. Apache Kafka is an excellent foundation for building an event-driven architecture. In this post, we discussed the key concepts of EDA, how Kafka implements the publish-subscribe model, and how to use Kafka to build an event-driven architecture. With Kafka, we can leverage its distributed design, low latency, and high throughput to build powerful, real-time systems that can react to changes in real-time."
    },
    "finish_reason": "stop"
   }
  ],
  "usage": {
   "prompt_tokens": 2235,
   "completion_tokens": 1160,
   "total_tokens": 3395
  }
 }
}