---
title: "The Magic of High-Level Streams"
date: 2023-06-02T05:25:04.209Z
tags: ["rust","streams","data streams"]
---


Asynchronous programming is hard. When dealing with high-performance systems that need to process large data streams, it can be even harder. But Rust has a sweet solution that makes working with data streams an enjoyable experience: high-level, functional streams.

In Rust 1.0, Rust introduced `mio` as an asynchronous I/O library, and with Rust 1.39, Rust introduced `async/await`, which makes it even more pleasant to work with asynchronous programming and event-driven programming.

In this article, we will be exploring Rust's high-level streams by building an example that demonstrates how to work with data streams in Rust.

# Introduction to high-level streams

Rust's `Stream` trait provides a definition for a sequence of asynchronous values, most typically used with data streams. A stream processes data in chunks and can be infinite, meaning it is theoretically limited by memory size or available space.

Streams provide a nice abstraction for handling asynchronous data and make it possible to implement backpressure and other flow-control mechanisms.

Rust's `futures` library provides a `Stream` trait and also defines useful combinators that can be useful when working with streams. The `Stream` trait represents an asynchronous sequence of values.

An asynchronous sequence of items can be generated by returning a `Stream` instead of an iterator. This allows us to represent very large or even infinite sequences of data that would not fit in memory.

Let's create a data stream using Rust streams that generates random numbers every 500ms.

```rust
use futures::{Stream, pin_mut, stream::{self, Interval}};
use rand::prelude::*;

async fn generate_data_stream() -> impl Stream<Item = i32> {
    let tick = Interval::new(Duration::from_millis(500));
    stream::unfold(0, move |_| {
        let mut rng = thread_rng();
        let num = rng.gen_range(1, 101);
        Some((num, async { tick.next().await },))
    })
    .map(|(num, _)| num)
}

#[tokio::main]
async fn main() {
    let data_stream = generate_data_stream();
    pin_mut!(data_stream);

    while let Some(num) = data_stream.next().await {
        println!("{}", num);
    }
}
```

This generates a data stream that generates a random number every 500 milliseconds using `async/await` and Rust streams. We create an `Interval` that will keep on ticking for every 500 milliseconds and store it in `tick`. We will pass `tick` as a state to the `stream::unfold` function along with a closure that generates random numbers using the `rand` crate, creates a tuple with the random number and the next tick, and returns it as an optional value to `stream::unfold`.

In the main function, we get the stream of data using `generate_data_stream()`, pin it to the stack using `pin_mut`, and loop through the data stream using `while let` and `data_stream.next().await`.

Now let's learn about backpressure and how Rust's streams handle it.

# Backpressure

Backpressure is the ability to manage the rate where a data source produces data and the ability of a data consumer to tell the data source how much data it can receive at any given time. In other words, it's like placing your finger on a garden hose's tip to regulate how much water comes out.

Rust supports backpressure through the `futures::stream::Stream` trait and its `futures::stream::StreamExt` trait. `StreamExt` defines combinators that allow us to create a backpressure mechanism to handle data streams with the following two combinators:

- The `futures::stream::StreamExt::buffer()` combinator allows us to define an upper bound on the number of items a stream can buffer before pausing the source. If the buffer size exceeds the defined capacity, backpressure will be applied.

- The `futures::stream::StreamExt::throttle()` combinator allows us to define a minimum interval time between items.

Let's see how these combinators work with a code snippet that generates random numbers every 500 milliseconds and prints them out with a buffer size of 3.

```rust
use futures::{Stream, stream::{self, Interval}, StreamExt};
use rand::prelude::*;
use std::time::{Duration, Instant};

async fn generate_data_stream() -> impl Stream<Item = i32> {
    let tick = Interval::new(Duration::from_millis(500));
    stream::unfold(0, move |_| {
        let mut rng = thread_rng();
        let num = rng.gen_range(1, 101);
        Some((num, async { tick.next().await },))
    })
    .map(|(num, _)| num)
}

#[tokio::main]
async fn main() {
    let data_stream = generate_data_stream().buffer_unordered(3);
    let mut interval = Interval::new_at(Instant::now(), Duration::from_secs(1));
    while let Some(_) = interval.next().await {
        if let Some(num) = data_stream.next().await {
            println!("{}", num);
        }
    }
}
```

This generates a data stream that generates a random number every 500 milliseconds and prints it out with a buffer size of 3. We used the `buffer_unordered` function with a size of 3 to apply backpressure when the buffer size is greater than 3.

Functions that return a stream are useful for working with data streams that are too large to fit into memory and when the result cannot be determined immediately.

Rust's high-level streams provide a powerful abstraction for handling asynchronous data. By providing combinators that can help to apply useful backpressure mechanisms, we can write more efficient and performant applications.